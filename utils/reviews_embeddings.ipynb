{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient, UpdateOne\n",
    "from google.cloud import translate_v2 as translate\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from bson.objectid import ObjectId\n",
    "import html\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "MAX_WORKERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGODB_URI = (\n",
    "    os.environ[\"MONGODB_URI\"]\n",
    "    if \"MONGODB_URI\" in os.environ\n",
    "    else input(\"MongoDB Connection String: \")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(MONGODB_URI)\n",
    "db = client[\"genai_inventory_classification\"]\n",
    "collection = db[\"reviews\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_client = translate.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text):\n",
    "    target = \"en\"\n",
    "    source = \"pt\"\n",
    "    if not text: \n",
    "        return None\n",
    "    translated_text = translate_client.translate(text, target_language=target, source_language=source)[\"translatedText\"]\n",
    "    return html.unescape(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(documents):\n",
    "    \"\"\"Translate a batch of documents in parallel and update MongoDB using bulk_write().\"\"\"\n",
    "    updates = []\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        future_to_doc = {}\n",
    "\n",
    "        # Submit translation tasks\n",
    "        for doc in documents:\n",
    "            doc_id = doc[\"_id\"]\n",
    "            title_original = doc.get(\"titleOriginal\")\n",
    "            message_original = doc.get(\"messageOriginal\")\n",
    "\n",
    "            title_future = executor.submit(translate_text, title_original) if title_original else None\n",
    "            message_future = executor.submit(translate_text, message_original) if message_original else None\n",
    "\n",
    "            if title_future:\n",
    "                future_to_doc[title_future] = (doc_id, \"title\")\n",
    "            else:\n",
    "                updates.append(UpdateOne({\"_id\": doc_id}, {\"$set\": {\"title\": None}})) \n",
    "\n",
    "            if message_future:\n",
    "                future_to_doc[message_future] = (doc_id, \"message\")\n",
    "            else:\n",
    "                updates.append(UpdateOne({\"_id\": doc_id}, {\"$set\": {\"message\": None}})) \n",
    "\n",
    "        # Collect results\n",
    "        for future in as_completed(future_to_doc):\n",
    "            doc_id, field = future_to_doc[future]\n",
    "            try:\n",
    "                translated_text = future.result()\n",
    "                updates.append(UpdateOne({\"_id\": doc_id}, {\"$set\": {field: translated_text}}))\n",
    "            except Exception as e:\n",
    "                print(f\"Error translating {field} for document {doc_id}: {e}\")\n",
    "\n",
    "    # Perform bulk write to update MongoDB\n",
    "    if updates:\n",
    "        collection.bulk_write(updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents to process: 5158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Reviews: 100%|██████████| 5158/5158 [02:11<00:00, 39.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filter = {\"$or\": [{\"title\": {\"$exists\": False}}, {\"message\": {\"$exists\": False}}]}\n",
    "#filter = {\"$and\": [{\"_id\": ObjectId(\"67cf17d7c1af94d1b49cbed1\")},{\"$or\": [{\"title\": {\"$exists\": False}}, {\"message\": {\"$exists\": False}}]}]}\n",
    "total_docs = collection.count_documents(filter)\n",
    "print(f\"Total documents to process: {total_docs}\")\n",
    "\n",
    "with tqdm(total=total_docs, desc=\"Translating Reviews\") as pbar:\n",
    "    while True:\n",
    "        # Fetch next batch of unprocessed documents\n",
    "        documents = list(collection.find(\n",
    "            filter,\n",
    "            {\"_id\": 1, \"titleOriginal\": 1, \"messageOriginal\": 1}\n",
    "        ).limit(BATCH_SIZE))\n",
    "\n",
    "        if not documents:\n",
    "            break  # No more documents to process\n",
    "\n",
    "        process_batch(documents)\n",
    "        pbar.update(len(documents))  # Update progress bar\n",
    "\n",
    "print(\"Translation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_region = \"us-east-1\"\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=aws_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text):\n",
    "    \"\"\"Generate text embedding using AWS Bedrock Cohere model.\"\"\"\n",
    "    if not text.strip():  # If empty or whitespace\n",
    "        return None\n",
    "\n",
    "    payload = {\n",
    "        \"texts\": [text],\n",
    "        \"input_type\": \"search_document\",\n",
    "        \"embedding_types\": [\"float\"],    \n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            body=json.dumps(payload),\n",
    "            modelId=\"cohere.embed-english-v3\",\n",
    "            accept='*/*',\n",
    "            contentType=\"application/json\",\n",
    "        )\n",
    "        response_body = json.loads(response[\"body\"].read())\n",
    "        embeddings = response_body.get(\"embeddings\")\n",
    "        return embeddings[\"float\"][0]\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Error generating embedding: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(documents):\n",
    "    \"\"\"Generate embeddings in parallel and update MongoDB.\"\"\"\n",
    "    updates = []\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        future_to_doc = {}\n",
    "\n",
    "        for doc in documents:\n",
    "            doc_id = doc[\"_id\"]\n",
    "            title = doc.get(\"title\")\n",
    "            message = doc.get(\"message\")\n",
    "\n",
    "            if title is None and message is None:\n",
    "                # If both are None, set emb to None without calling AWS\n",
    "                updates.append(UpdateOne({\"_id\": doc_id}, {\"$set\": {\"emb\": None}}))\n",
    "            else:\n",
    "                combined_text = f\"{title or ''} {message or ''}\".strip()\n",
    "                future = executor.submit(generate_embedding, combined_text)\n",
    "                future_to_doc[future] = doc_id\n",
    "\n",
    "        # Collect results\n",
    "        for future in as_completed(future_to_doc):\n",
    "            doc_id = future_to_doc[future]\n",
    "            try:\n",
    "                embedding = future.result()\n",
    "                updates.append(UpdateOne({\"_id\": doc_id}, {\"$set\": {\"emb\": embedding}}))\n",
    "            except Exception as e:\n",
    "                tqdm.write(f\"Error processing document {doc_id}: {e}\")\n",
    "\n",
    "    # Perform bulk update in MongoDB\n",
    "    if updates:\n",
    "        collection.bulk_write(updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents to process: 5158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 5158/5158 [03:19<00:00, 25.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filter = {\"emb\": {\"$exists\": False}}\n",
    "#filter = {\"$and\": [{\"_id\": ObjectId(\"67cf17d7c1af94d1b49cbed1\")},{\"emb\": {\"$exists\": False}}]}\n",
    "total_docs = collection.count_documents(filter)\n",
    "print(f\"Total documents to process: {total_docs}\")\n",
    "\n",
    "with tqdm(total=total_docs, desc=\"Generating Embeddings\") as pbar:\n",
    "    while True:\n",
    "        # Fetch next batch of unprocessed documents\n",
    "        documents = list(collection.find(\n",
    "           filter,  # Only fetch documents without embeddings\n",
    "            {\"_id\": 1, \"title\": 1, \"message\": 1}\n",
    "        ).limit(BATCH_SIZE))\n",
    "\n",
    "        if not documents:\n",
    "            break  # No more documents to process\n",
    "\n",
    "        process_batch(documents)\n",
    "        pbar.update(len(documents))  # Update progress bar\n",
    "        time.sleep(1)  # Small delay to avoid excessive API calls\n",
    "\n",
    "print(\"Embedding generation completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
